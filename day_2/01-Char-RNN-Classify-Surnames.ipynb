{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "import json\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from vocabulary import Vocabulary\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "START_TOKEN = \"^\"\n",
    "END_TOKEN = \"_\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Definitions \n",
    "\n",
    "Data Model:\n",
    "- Raw data\n",
    "- Vectorizer\n",
    "- Vectorized Data\n",
    "- Data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe(x):\n",
    "    print(\"Type: {}\".format(x.type()))\n",
    "    print(\"Shape/size: {}\".format(x.shape))\n",
    "    print(\"Values: \\n{}\".format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RawSurnames(object):\n",
    "    def __init__(self, data_path, delimiter=\",\"):\n",
    "        self.data = pd.read_csv(data_path, delimiter=delimiter)\n",
    "\n",
    "    def get_data(self, filter_to_nationality=None):\n",
    "        if filter_to_nationality is not None:\n",
    "            return self.data[self.data.nationality.isin(filter_to_nationality)]\n",
    "        return self.data\n",
    "\n",
    "# vectorizer\n",
    "\n",
    "class SurnamesVectorizer(object):\n",
    "    def __init__(self, surname_vocab, nationality_vocab, max_seq_length):\n",
    "        self.surname_vocab = surname_vocab\n",
    "        self.nationality_vocab = nationality_vocab\n",
    "        self.max_seq_length = max_seq_length\n",
    "        \n",
    "    def save(self, filename):\n",
    "        vec_dict = {\"surname_vocab\": self.surname_vocab.get_serializable_contents(),\n",
    "                    \"nationality_vocab\": self.nationality_vocab.get_serializable_contents(),\n",
    "                    'max_seq_length': self.max_seq_length}\n",
    "\n",
    "        with open(filename, \"w\") as fp:\n",
    "            json.dump(vec_dict, fp)\n",
    "        \n",
    "    @classmethod\n",
    "    def load(cls, filename):\n",
    "        with open(filename, \"r\") as fp:\n",
    "            vec_dict = json.load(fp)\n",
    "\n",
    "        vec_dict[\"surname_vocab\"] = Vocabulary.deserialize_from_contents(vec_dict[\"surname_vocab\"])\n",
    "        vec_dict[\"nationality_vocab\"] = Vocabulary.deserialize_from_contents(vec_dict[\"nationality_vocab\"])\n",
    "        return cls(**vec_dict)\n",
    "\n",
    "    @classmethod\n",
    "    def fit(cls, surname_df):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        surname_vocab = Vocabulary(use_unks=False,\n",
    "                                   use_mask=True,\n",
    "                                   use_start_end=True,\n",
    "                                   start_token=START_TOKEN,\n",
    "                                   end_token=END_TOKEN)\n",
    "\n",
    "        nationality_vocab = Vocabulary(use_unks=False, use_start_end=False, use_mask=False)\n",
    "\n",
    "        max_seq_length = 0\n",
    "        for index, row in surname_df.iterrows():\n",
    "            surname_vocab.add_many(row.surname)\n",
    "            nationality_vocab.add(row.nationality)\n",
    "\n",
    "            if len(row.surname) > max_seq_length:\n",
    "                max_seq_length = len(row.surname)\n",
    "        max_seq_length = max_seq_length + 2\n",
    "\n",
    "        return cls(surname_vocab, nationality_vocab, max_seq_length)\n",
    "\n",
    "    @classmethod\n",
    "    def fit_transform(cls, surname_df, split='train'):\n",
    "        vectorizer = cls.fit(surname_df)\n",
    "        return vectorizer, vectorizer.transform(surname_df, split)\n",
    "\n",
    "    def transform(self, surname_df, split='train'):\n",
    "\n",
    "        df = surname_df[surname_df.split==split].reset_index()\n",
    "        n_data = len(df)\n",
    "        \n",
    "        x_surnames = np.zeros((n_data, self.max_seq_length), dtype=np.int64)\n",
    "        y_nationalities = np.zeros(n_data, dtype=np.int64)\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            vectorized_surname = list(self.surname_vocab.map(row.surname, \n",
    "                                                             include_start_end=True))\n",
    "            x_surnames[index, :len(vectorized_surname)] = vectorized_surname\n",
    "            y_nationalities[index] = self.nationality_vocab[row.nationality]\n",
    "\n",
    "        return VectorizedSurnames(x_surnames, y_nationalities)\n",
    "\n",
    "# vec data\n",
    "\n",
    "\n",
    "class VectorizedSurnames(Dataset):\n",
    "    def __init__(self, x_surnames, y_nationalities):\n",
    "        self.x_surnames = x_surnames\n",
    "        self.y_nationalities = y_nationalities\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_surnames)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return {'x_surnames': self.x_surnames[index],\n",
    "                'y_nationalities': self.y_nationalities[index],\n",
    "                'x_lengths': len(self.x_surnames[index].nonzero()[0])}\n",
    "\n",
    "# data generator\n",
    "\n",
    "def generate_batches(dataset, batch_size, shuffle=True,\n",
    "                     drop_last=True, device=\"cpu\"): \n",
    "    \"\"\"\n",
    "    A generator function which wraps the PyTorch DataLoader. It will \n",
    "      ensure each tensor is on the write device location.\n",
    "    \"\"\"\n",
    "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
    "                            shuffle=shuffle, drop_last=drop_last)\n",
    "\n",
    "    for data_dict in dataloader:\n",
    "        out_data_dict = {}\n",
    "        for name, tensor in data_dict.items():\n",
    "            out_data_dict[name] = data_dict[name].to(device)\n",
    "        yield out_data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class definitions for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_parameter(*size):\n",
    "    out = torch.randn(*size, requires_grad=True, dtype=torch.float32)\n",
    "    torch.nn.init.xavier_normal_(out)\n",
    "    print(out)\n",
    "    return nn.Parameter(out)\n",
    "\n",
    "def column_gather(y_out, x_lengths):\n",
    "    '''Get a specific vector from each batch datapoint in `y_out`.\n",
    "\n",
    "    More precisely, iterate over batch row indices, get the vector that's at\n",
    "    the position indicated by the corresponding value in `x_lengths` at the row\n",
    "    index.\n",
    "\n",
    "    Args:\n",
    "        y_out (torch.FloatTensor, torch.cuda.FloatTensor)\n",
    "            shape: (batch, sequence, feature)\n",
    "        x_lengths (torch.LongTensor, torch.cuda.LongTensor)\n",
    "            shape: (batch,)\n",
    "\n",
    "    Returns:\n",
    "        y_out (torch.FloatTensor, torch.cuda.FloatTensor)\n",
    "            shape: (batch, feature)\n",
    "    '''\n",
    "    x_lengths = x_lengths.long().detach().cpu().numpy() - 1\n",
    "\n",
    "    out = []\n",
    "    for batch_index, column_index in enumerate(x_lengths):\n",
    "        out.append(y_out[batch_index, column_index])\n",
    "\n",
    "    return torch.stack(out)\n",
    "\n",
    "\n",
    "class ExplicitRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, batch_first=False):\n",
    "        super(ExplicitRNN, self).__init__()\n",
    "        self.W_in2hid = new_parameter(input_size, hidden_size)\n",
    "        self.W_hid2hid = new_parameter(hidden_size, hidden_size)\n",
    "            \n",
    "        self.b_hid = new_parameter(1, hidden_size)\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.batch_first = batch_first\n",
    "    \n",
    "    def _compute_next_hidden(self, x, h):\n",
    "        return F.tanh(x.matmul(self.W_in2hid) + \n",
    "                      h.matmul(self.W_hid2hid) + \n",
    "                      self.b_hid)\n",
    "\n",
    "    def forward(self, x_in, hid_t=None):\n",
    "        if self.batch_first:\n",
    "            batch_size, seq_size, feat_size = x_in.size()\n",
    "            x_in = x_in.permute(1, 0, 2)\n",
    "        else:\n",
    "            seq_size, batch_size, feat_size = x_in.size()\n",
    "\n",
    "        hiddens = []\n",
    "        if hid_t is None:\n",
    "            hid_t = torch.ones((batch_size, self.hidden_size))\n",
    "        \n",
    "        if x_in.is_cuda:\n",
    "            hid_t = hid_t.cuda()\n",
    "            \n",
    "        for t in range(seq_size):\n",
    "            x_t = x_in[t]\n",
    "            hid_t = self._compute_next_hidden(x_t, hid_t)\n",
    "            \n",
    "            hiddens.append(hid_t)\n",
    "        hiddens = torch.stack(hiddens)\n",
    "\n",
    "        if self.batch_first:\n",
    "            hiddens = hiddens.permute(1, 0, 2)\n",
    "\n",
    "        return hiddens\n",
    "    \n",
    "    \n",
    "class CharNN(nn.Module):\n",
    "    def __init__(self, embedding_size, in_vocab_size, out_vocab_size, hidden_size, \n",
    "                 batch_first=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            embedding_size (int): size of each embedding vector\n",
    "            in_vocab_size (int): number of input characters\n",
    "            out_vocab_size (int): number of characters to predict to\n",
    "            hidden_size (int): the intermediate representation size\n",
    "        \"\"\"\n",
    "        super(CharNN, self).__init__()\n",
    "        \n",
    "        self.emb = nn.Embedding(embedding_dim=embedding_size, num_embeddings=in_vocab_size, padding_idx=0)\n",
    "        self.fc = nn.Linear(in_features=hidden_size, out_features=out_vocab_size)\n",
    "        self.rnn = ExplicitRNN(input_size=embedding_size, hidden_size=hidden_size, \n",
    "                               batch_first=batch_first)\n",
    "    \n",
    "    \n",
    "    def forward(self, x_in, x_lengths=None, apply_softmax=False):\n",
    "        \"\"\"The forward pass of the classifier\n",
    "        \n",
    "        Args:\n",
    "            x_in (torch.Tensor): an input data tensor. \n",
    "                x_in.shape should be (batch, input_dim)\n",
    "            x_lengths\n",
    "            apply_softmax (bool): a flag for the softmax activation\n",
    "                should be false if used with the Cross Entropy losses\n",
    "        Returns:\n",
    "            the resulting tensor. tensor.shape should be (batch, output_dim)\n",
    "        \"\"\"\n",
    "        x_in = self.emb(x_in)\n",
    "        y_out = self.rnn(x_in)\n",
    "        \n",
    "        if x_lengths is not None:\n",
    "            y_out = column_gather(y_out, x_lengths)\n",
    "        else:\n",
    "            y_out = y_out[:, -1, :] \n",
    "\n",
    "        y_out = self.fc(y_out)\n",
    "\n",
    "        if apply_softmax:\n",
    "            y_out = F.softmax(y_out)\n",
    "            \n",
    "        return y_out\n",
    "\n",
    "    \n",
    "def compute_accuracy(y_pred, y_target):\n",
    "    _, y_pred_indices = y_pred.max(dim=1)\n",
    "    n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n",
    "    return n_correct / len(y_pred_indices) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make, Train, and Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = Namespace(\n",
    "    surname_csv=\"../data/surnames.csv\",\n",
    "    batch_size = 128,\n",
    "    cuda=True,\n",
    "    learning_rate=0.001,\n",
    "    num_epochs=10,\n",
    "    load_zoo_model=True,\n",
    "    zoo={\n",
    "        'filename': '../modelzoo/charnn_emb16_hid64_surnames_classify.state',\n",
    "        'vocab': '../modelzoo/surnames_classify.vocab',\n",
    "        'comments': 'pre-trained surname classifier',\n",
    "        'parameters': {\n",
    "            'embedding_size': 16,\n",
    "            'hidden_size': 64\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# Check CUDA\n",
    "if not torch.cuda.is_available():\n",
    "    args.cuda = False\n",
    "\n",
    "print(\"Using CUDA: {}\".format(args.cuda))\n",
    "\n",
    "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "args.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional: set this to false to learn from scratch!\n",
    "# args.load_zoo_model = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vectorizer!\n",
      "tensor([[ 0.2503,  0.1111, -0.0163,  ...,  0.0687,  0.0419, -0.0259],\n",
      "        [-0.0510, -0.0639, -0.0596,  ...,  0.0809,  0.3548, -0.0684],\n",
      "        [-0.0148,  0.0051,  0.2042,  ..., -0.1691, -0.0335, -0.2904],\n",
      "        ...,\n",
      "        [ 0.2471,  0.0282,  0.1586,  ...,  0.0560, -0.1007,  0.0733],\n",
      "        [ 0.1122, -0.0333,  0.3124,  ..., -0.0560,  0.2706,  0.0114],\n",
      "        [-0.4297, -0.1686, -0.3285,  ...,  0.1568, -0.0356, -0.0637]],\n",
      "       requires_grad=True)\n",
      "tensor([[-0.0664, -0.0243,  0.0550,  ...,  0.0349,  0.0688, -0.1134],\n",
      "        [-0.1259, -0.2254,  0.2186,  ..., -0.0719, -0.0496, -0.1214],\n",
      "        [ 0.1307, -0.1541, -0.0197,  ..., -0.0721,  0.0594, -0.0145],\n",
      "        ...,\n",
      "        [ 0.0697,  0.0156,  0.1081,  ...,  0.0577,  0.0809,  0.0200],\n",
      "        [-0.0989, -0.0821,  0.0911,  ...,  0.2420,  0.0234, -0.1420],\n",
      "        [ 0.1905, -0.1189, -0.0759,  ..., -0.1532, -0.1404,  0.0313]],\n",
      "       requires_grad=True)\n",
      "tensor([[ 0.0377, -0.2353,  0.2367,  0.1370, -0.0610, -0.0273,  0.0739, -0.0807,\n",
      "         -0.0486, -0.0178,  0.0086,  0.0575,  0.0121, -0.2588, -0.1763, -0.1840,\n",
      "         -0.1256, -0.0237, -0.0295,  0.0590,  0.0074,  0.0431,  0.0468,  0.1603,\n",
      "         -0.0182, -0.0958, -0.2530, -0.3484, -0.0432, -0.0190, -0.0015,  0.1706,\n",
      "          0.2906,  0.1504,  0.1219, -0.0138, -0.1176,  0.2989, -0.1912,  0.0736,\n",
      "          0.0564, -0.2130,  0.0173, -0.1263, -0.2897, -0.1449, -0.0594,  0.0632,\n",
      "         -0.1494,  0.0057, -0.0775, -0.1313, -0.0929,  0.0395, -0.1271,  0.1603,\n",
      "         -0.1441, -0.2015, -0.2555, -0.1007, -0.0384,  0.2157, -0.0673,  0.1096]],\n",
      "       requires_grad=True)\n",
      "16\n",
      "64\n",
      "90\n",
      "Loading state dict!\n"
     ]
    }
   ],
   "source": [
    "raw_data = RawSurnames(args.surname_csv).get_data()\n",
    "\n",
    "if os.path.exists(args.zoo['vocab']):\n",
    "    vectorizer = SurnamesVectorizer.load(args.zoo['vocab'])\n",
    "    print(\"Loading vectorizer!\")\n",
    "else:\n",
    "    vectorizer = SurnamesVectorizer.fit(raw_data)\n",
    "    print(\"Creating a new vectorizer.\")\n",
    "    \n",
    "train_dataset = vectorizer.transform(raw_data, split='train')\n",
    "test_dataset = vectorizer.transform(raw_data, split='test')\n",
    "\n",
    "zoo_params = args.zoo['parameters']\n",
    "\n",
    "net = CharNN(embedding_size=zoo_params['embedding_size'], \n",
    "             hidden_size=zoo_params['hidden_size'],\n",
    "             in_vocab_size=len(vectorizer.surname_vocab), \n",
    "             out_vocab_size=len(vectorizer.nationality_vocab),\n",
    "             batch_first=True)\n",
    "\n",
    "print(zoo_params['embedding_size'])\n",
    "print(zoo_params['hidden_size'])\n",
    "print(len(vectorizer.surname_vocab))\n",
    "if args.load_zoo_model and os.path.exists(args.zoo['filename']):\n",
    "    print(\"Loading state dict!\")\n",
    "    net.load_state_dict(torch.load(args.zoo['filename'], \n",
    "                                   map_location=lambda storage, loc: storage))\n",
    "else:\n",
    "    print(\"Using newly initiated network!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d163b7f910104c8e8e075e839914cb94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epochs', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc066cb610514d6ab637b07be58addbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='training', max=125), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7350f840b91247f0ae086875bd385917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='test', max=31), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/torch/nn/functional.py:995: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n",
      "torch.Size([128, 22])\n"
     ]
    }
   ],
   "source": [
    "print(\"Device is \".format(args.device.type))\n",
    "net = net.to(args.device)\n",
    "    \n",
    "# optimizer\n",
    "    \n",
    "optimizer = optim.Adam(net.parameters(), lr=args.learning_rate)\n",
    "\n",
    "# loss function / criterion with class-weighted modifications\n",
    "\n",
    "class_counts = raw_data.nationality.value_counts().to_dict()\n",
    "sorted_counts = sorted(class_counts.items(), key=lambda item: vectorizer.nationality_vocab[item[0]])\n",
    "class_weights = 1.0 / torch.tensor([count for _, count in sorted_counts], dtype=torch.float32)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights.to(args.device))\n",
    "\n",
    "# progress bars\n",
    "\n",
    "epoch_bar = tqdm_notebook(desc='epochs', total=args.num_epochs, position=1)\n",
    "\n",
    "num_train_batches = len(train_dataset) // args.batch_size\n",
    "train_bar = tqdm_notebook(desc='training', total=num_train_batches, position=2)\n",
    "\n",
    "num_test_batches = len(test_dataset) // args.batch_size\n",
    "test_bar = tqdm_notebook(desc='test', total=num_test_batches, position=3)\n",
    "\n",
    "# history \n",
    "\n",
    "train_loss_history = []\n",
    "train_accuracy_history = []\n",
    "\n",
    "test_loss_history = []\n",
    "test_accuracy_history = []\n",
    "\n",
    "try:\n",
    "    for _ in range(args.num_epochs):\n",
    "        batch_generator = generate_batches(train_dataset, batch_size=args.batch_size,\n",
    "                                           device=args.device)\n",
    "        \n",
    "        per_epoch_loss = []\n",
    "        per_epoch_accuracy = []\n",
    "        \n",
    "        net.train()\n",
    "            \n",
    "        for batch_dict in batch_generator:\n",
    "            # step 1\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # step 2\n",
    "            print((batch_dict['x_surnames']).shape)\n",
    "            y_pred = net(batch_dict['x_surnames'], batch_dict['x_lengths'])\n",
    "            y_target = batch_dict['y_nationalities']\n",
    "            \n",
    "            # step 3\n",
    "            loss = criterion(y_pred, y_target)\n",
    "  \n",
    "            # step 4\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # bonus steps: bookkeeping \n",
    "            \n",
    "            per_epoch_loss.append(loss.item())\n",
    "            accuracy = compute_accuracy(y_pred, y_target)\n",
    "            per_epoch_accuracy.append(accuracy)\n",
    "\n",
    "            train_bar.update()\n",
    "            \n",
    "            train_bar.set_postfix(loss=per_epoch_loss[-1], \n",
    "                                  accuracy=per_epoch_accuracy[-1])\n",
    "            \n",
    "        train_loss_history.append(np.mean(per_epoch_loss))\n",
    "        train_accuracy_history.append(np.mean(per_epoch_accuracy))\n",
    "        \n",
    "        # loop over test dataset\n",
    "        \n",
    "        batch_generator = generate_batches(test_dataset, batch_size=args.batch_size, \n",
    "                                           device=args.device)\n",
    "        \n",
    "        per_epoch_loss = []\n",
    "        per_epoch_accuracy = []\n",
    "            \n",
    "        # set it to eval mode; this turns stochastic functions off\n",
    "#         net.eval()\n",
    "            \n",
    "        for batch_dict in batch_generator:\n",
    "            \n",
    "            # step 1: compute output\n",
    "            y_pred = net(batch_dict['x_surnames'], batch_dict['x_lengths'])\n",
    "            y_target = batch_dict['y_nationalities'] \n",
    "            \n",
    "            # step 2: compute whatever metrics; here we compute loss and accuracy\n",
    "            \n",
    "            loss = criterion(y_pred, y_target)\n",
    "            per_epoch_loss.append(loss.item())\n",
    "            accuracy = compute_accuracy(y_pred, y_target)\n",
    "            per_epoch_accuracy.append(accuracy)\n",
    "\n",
    "            test_bar.update()\n",
    "            \n",
    "            test_bar.set_postfix(loss=per_epoch_loss[-1], \n",
    "                                 accuracy=per_epoch_accuracy[-1])\n",
    "            \n",
    "        test_loss_history.append(np.mean(per_epoch_loss))\n",
    "        test_accuracy_history.append(np.mean(per_epoch_accuracy))\n",
    "        \n",
    "        # update bars\n",
    "        \n",
    "        epoch_bar.set_postfix(train_loss=train_loss_history[-1], \n",
    "                              train_accuracy=train_accuracy_history[-1],\n",
    "                              test_loss=test_loss_history[-1],\n",
    "                              test_accuracy=test_accuracy_history[-1])\n",
    "        epoch_bar.update()\n",
    "        test_bar.n = 0\n",
    "        train_bar.n = 0\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fc8cd0fb208>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss_history, label='train loss')\n",
    "plt.plot(test_loss_history, label='test loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fc8cc8c6780>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_accuracy_history, label='train accuracy')\n",
    "plt.plot(test_accuracy_history, label='test accuracy')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_surname(surname):\n",
    "    surname_indices = list(vectorizer.surname_vocab.map(surname, include_start_end=True))\n",
    "    surname_vector = torch.tensor(surname_indices, dtype=torch.int64).unsqueeze(dim=0)\n",
    "    surname_length = torch.tensor([len(surname_indices)], dtype=torch.int64)\n",
    "    return surname_vector, surname_length\n",
    "    \n",
    "def predict_nationality(net, surname):\n",
    "    net = net.to(\"cpu\")\n",
    "    surname_vector, surname_length = vectorize_surname(surname)\n",
    "    y_prediction = net(surname_vector, surname_length)\n",
    "    _, nationality_index = y_prediction.max(dim=1)\n",
    "    return vectorizer.nationality_vocab.lookup(nationality_index.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'japanese'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_nationality(net, 'satoshi nakamoto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dutch'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_nationality(net, 'kah siong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dutch'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_nationality(net, 'bismarck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scottish'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_nationality(net, 'anderson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model\n",
    "torch.save(net.state_dict(), '01-char-rnn-classify-surnames.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "index out of range at /pytorch/aten/src/TH/generic/THTensorMath.cpp:352",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-847a72d537d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdummy_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m22\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"01-Char-RNN-Classify-Surnames.onnx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/onnx/__init__.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, aten, export_raw_ir, operator_export_type)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0moperator_export_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOperatorExportTypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mONNX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     _export(model, args, f, export_params, verbose, training, input_names, output_names,\n\u001b[0;32m---> 94\u001b[0;31m             operator_export_type=operator_export_type)\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, example_outputs, propagate)\u001b[0m\n\u001b[1;32m    224\u001b[0m                                                \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                                                \u001b[0moutput_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator_export_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m                                                example_outputs, propagate)\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;31m# TODO: Don't allocate a in-memory string for the protobuf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_model_to_graph\u001b[0;34m(model, args, f, verbose, training, input_names, output_names, operator_export_type, example_outputs, propagate)\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\'forward\\' method must be a script method'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_trace_and_get_graph_from_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_unique_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_trace_and_get_graph_from_model\u001b[0;34m(model, args, training)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;31m# training mode was.)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mset_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trace_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0morig_state_dict_keys\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_unique_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't stop after throw()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36mset_training\u001b[0;34m(model, mode)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mold_mode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_trace_and_get_graph_from_model\u001b[0;34m(model, args, training)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;31m# training mode was.)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mset_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trace_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0morig_state_dict_keys\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_unique_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/jit/__init__.py\u001b[0m in \u001b[0;36mget_trace_graph\u001b[0;34m(f, args, kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mLegacyTracedModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/jit/__init__.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0m_tracing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mtrace_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_trace_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtrace_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0mout_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0m_tracing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tracing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0mtracing_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_traced_module_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m             \u001b[0mtracing_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-df949dfd4948>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_in, x_lengths, apply_softmax)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mthe\u001b[0m \u001b[0mresulting\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0mshould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mx_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0my_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tracing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0mtracing_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_traced_module_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m             \u001b[0mtracing_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    108\u001b[0m         return F.embedding(\n\u001b[1;32m    109\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: index out of range at /pytorch/aten/src/TH/generic/THTensorMath.cpp:352"
     ]
    }
   ],
   "source": [
    "# from torch.autograd import Variable\n",
    "# import torch.onnx\n",
    "# import torchvision\n",
    "# dummy_input = Variable(torch.randn(128,22))\n",
    "# torch.onnx.export(net, dummy_input.long(), \"01-Char-RNN-Classify-Surnames.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
